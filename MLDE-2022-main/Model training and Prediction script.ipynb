{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459768e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\Perry_Lu\\Desktop\\ebm\\正课\\课程\\MLDE\\IMA\\data\\brazilian-ecommerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d64323",
   "metadata": {},
   "source": [
    "# Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971a529",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a089ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "# Tuning hyperparameters for f1_macro\n",
      "\n",
      "\n",
      "Best parameters set found on the training set:\n",
      "{'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 7}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classification\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "dataset = dataset.dropna().reset_index(drop=True)\n",
    "X = dataset.iloc[:,2:6].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "print(set(y))\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)#数据集比例划分\n",
    "\n",
    "# Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = [{\n",
    "                     'max_depth': [3, 5, 7],\n",
    "                     'min_samples_split': [3, 5, 7],\n",
    "                     'max_features': [\"sqrt\", \"log2\", None]}]\n",
    "\n",
    "scores = [ 'f1_macro']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyperparameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "    clf = GridSearchCV(RandomForestClassifier(class_weight=\"balanced\"), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters set found on the training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c1a03",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57e5c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix is: \n",
      "[[ 1222  3636]\n",
      " [  611 17019]]\n",
      "f1_score is: 0.8890688259109312\n"
     ]
    }
   ],
   "source": [
    "#  Fitting Random Forest to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0,class_weight = 'balanced',max_depth= 3, max_features= 'sqrt', min_samples_split= 7 )\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f'confusion_matrix is: \\n{cm}')\n",
    "print(f'f1_score is: {f1_score(y_test,y_pred,average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f8353",
   "metadata": {},
   "source": [
    "# 3Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf3c82",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34780e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n",
      "# Tuning hyperparameters for f1_macro\n",
      "\n",
      "\n",
      "Best parameters set found on the training set:\n",
      "{'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 3}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classification\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('dataset.csv')\n",
    "dataset = dataset.dropna().reset_index(drop=True)\n",
    "X = dataset.iloc[:,2:6].values\n",
    "y = dataset.iloc[:,-2].values\n",
    "print(set(y))\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)#数据集比例划分\n",
    "\n",
    "# Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = [{\n",
    "                     'max_depth': [3, 5, 7],\n",
    "                     'min_samples_split': [3, 5, 7],\n",
    "                     'max_features': [\"sqrt\", \"log2\", None]}]\n",
    "\n",
    "scores = ['f1_macro']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyperparameters for %s\" % score)\n",
    "    print(\"\\n\")\n",
    "    clf = GridSearchCV(RandomForestClassifier(class_weight=\"balanced\"), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters set found on the training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846faf3",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf31d20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix is: \n",
      "[[1342 1185 2331]\n",
      " [ 264 1501 2724]\n",
      " [ 594 3780 8767]]\n",
      "f1_score is: 0.4348687931928312\n"
     ]
    }
   ],
   "source": [
    "#  Fitting Random Forest to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0,class_weight = 'balanced',max_depth= 7, max_features= 'sqrt', min_samples_split= 3 )\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f'confusion_matrix is: \\n{cm}')\n",
    "print(f'f1_score is: {f1_score(y_test,y_pred,average=\"macro\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
